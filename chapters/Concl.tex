\chapter{Conclusions}
\label{Chap:Concl}
The evolution of music technology and industry is requiring novel approaches to assist the users in the retrieval and recommendation of musical items in the current huge music libraries. In this thesis, we addressed the design and development of such approaches by following a generalizing schema based on a linking function between the signal domain, that represents the musical content, and the semantic domain, that represents its high-level meaning. 

The formalization of the three elements, i.e., the signal domain, the linking function and the semantic domain, raises several issues, including: the understanding of the musical properties, the design of the techniques to automatically capture them, the ambiguity and complexity of the music semantics and the emulation of the perception process for music. We employed techniques from the state of the art of MIR to address these issues.

We devoted the first part of our thesis to analyze and formalize the three elements of the schema. In this stage, we conducted two research activities that involved the formalization of the signal domain and the expansion of the semantic domain.

%The studies on NMP aims Internet connections introduce some latency that affect the quality of the performance of the musicians. 
With respect to the signal domain, as discussed in Chapter \ref{Chap:LLFs}, we investigated feature-based formalization. We first considered hand-crafted and model-based features, which capture the low-level properties of the audio signal. In order to develop a better understanding of the hand-crafted features, in Section \ref{sec:NMP} we conducted a study on the scenario of Networked Music Performances (NMPs), which allow musicians to play, rehearse or record live sessions from different physical locations through an Internet connection. 
We addressed the scenario from the perspective of the music signal, and we conducted a set of experiments to analyze how the quality of the performance is affected by the properties of the music, 
i.e., by the feature representation of the signal domain. We collected a set of hand-crafted and model-based features, which automatically extract specific audio characteristics from the spectrum of the signal, the music score or its symbolic representation, and we estimated how musical properties affect the overall quality of the performances. In particular, we found that the quality improves for NMPs with slow tempi and low rhythmic complexities, and deteriorates when noisy instruments are involved. These information can be effectively used to estimate the expected quality of a NMP for a certain network delay given the properties of the parts and of the instruments involved.

The extraction of hand-crafted and model-based features require to know in advance which musical properties characterize the addressed problem and which feature can capture such properties. In some scenarios, however, the involved musical properties are not clear or only vaguely deducible. For these scenarios, we considered a formalization of the signal domain based on deep learning techniques, which are able to automatically extract a set of salient features from the audio signal. 

The feature-based formalization of the signal domain can be interpreted by researchers and musicologists to address a number of problems related with audio and music, but they carry an extremely low level of semantics, and are therefore not abstract enough to be directly used for the description of the semantic domain. The formalization of the semantic domain is indeed highly complex, due to the various high-level aspects of music in which the users might be interested. 

In Chapter \ref{Chap:HLFs} we reviewed the main techniques used to define the so-called High-Level Features (HLFs) for the semantic description of music. We first considered the formalization of the musical structure of songs, which carry a great amount of semantics. We then discussed the two main approaches for the semantic description, which are the categorical and the dimensional approach. The former defines whether a song can be annotated with a certain descriptor, while the latter defines a graded description of the song.
%We reviewed in particular the 
%
%, the set of dimensional descriptors is usually referred to \textit{semantic}The latter approach was extensively used in the literature to formalize a specific aspect %In the literature, this latter approach was extensively used to formalize a specific aspect 
%of the semantic domain (e.g., mood, genre) as a semantic model, which define a set of graded descriptors. 

The mood is one of the main aspects in music description, due to the ability of music to convey emotions. With this regard, a group of psychologists developed the Valence-Arousal dimensional model, which allows to map the emotional-related descriptors in a dimensional space and to define a metric of distance related to the semantic similarity among terms. The ANEW dataset, composed of 2,476 emotional-related terms annotated in the Valence-Arousal space, is one of the most helpful and widely employed resource within the MIR community for mood-related tasks. However, the ANEW dataset was not designed for music purposes and the generic semantics of mood might not apply to the description of music.

With this problem in mind, in Section \ref{sec:HLFs:ANEW} we conducted a study in order to make the ANEW dataset capable of bearing more relevance to the music description. We explored a high-dimensional, and possibly non-linear, space from the ANEW using kernel expansion techniques, and we then shaped the obtained space taking advantages of distance learning techniques. In particular, we shaped the high-dimensional space by applying a set of constraints computed from manual annotations of musical items. We proved that the new high-dimensional space, drawn and learned directly from the ANEW dataset, is capable of organizing the emotional-related descriptors in a way that is closer to the organization made by people. 

With respect to the linking function, as discussed in Chapter \ref{Chap:ML}, we reviewed the main approaches for its modeling and design, depending on the complexity and available knowledge of the addressed problem. If the problem is rather simple and the relationship between signal and semantic domain is known, rule-based techniques can be employed. In our review, we focused on techniques for the automatic analysis of the musical structure. If the problem is harder to formalize and the relationship between the two domains involve the modeling of the human perception from the sensory information to the intellectual comprehension of the musical content, the linking function can be designed as a predictive model using machine learning techniques.

We focused on two broad categories of machine learning techniques: the classifiers, that can be used to learn the music semantics when it is formalized with the categorical approach; and the regressors, that are feasible to predict values withing a continuous range, as required for the dimensional approach. 

We considered a generalization of the novel approaches to assist the users in the retrieval of musical items. Therefore, we devoted the second part of this thesis to address four application scenarios, progressively increasing the complexity of the formalization of the signal and semantic domains and of the linking function.

We firstly experimented the schema in Chapter \ref{Chap:MSA} to address the problem of automatic Music Structure Analysis (MSA). The musical structure has been extensively employed in the Western popular music and its semantic domain is in fact well formalized. In particular, we investigated the detection of boundaries between the sections. While traditional approach for MSA rely on the extraction of hand-crafted or model-based features from the music signal, we proposed an approach based on unsupervised learned features using a Deep Belief Network. We fed several rule-based techniques with the learned features, and we compared this approach with the same techniques fed with hand-crafted features. We validated the approach by using a metric of the correct detected boundaries using two levels of tolerance. On the one side, for the lower level of tolerance, the learned features achieved slightly worse results than the hand-crafted ones. On the other side, for the higher level of tolerance, the learned features achieved far better results than the ones obtained with hand-crafted features. From this scenario, we could assert that the learned features provided an effective representation of the signal domain for the analysis of the musical structure. 

In the MSA scenario, we could use rule-based techniques to properly link the signal and the semantic domain together because of the complete formalization of the semantic domain and the rather comprehensive knowledge of the addressed problem. However, bridging the gap between the signal and semantic domain often involves to model the human perception, which is a hard task. The use of machine learning techniques can help to address the task by providing automatic systems to learn the linking function. In this regard, we addressed two application scenarios for the task of automatic music description following the categorical and dimensional approach.

The categorical approach was addressed in Chapter \ref{Chap:Bootleg}, for the task of automatic detection of bootlegs, i.e., unauthorized recordings of a live performance. We formalized the semantic domain of the problem as a set of disjoint categories: studio recordings, live performances and bootlegs. This use case was not only useful for forensic purposes, but also to provide a description of the process that generated and produced a song. The scenario presented a number of challenges, since the signal domain is unclear and the linking function is unknown. In our study, we used unsupervised learned features to formalize the signal domain, which was linked to the semantic domain by means of a machine learning algorithm. This approach proved to be extremely effective and to strongly outperform the same approach based on hand-crafted or model-based features. Our system achieved an accuracy over $90\%$, which makes the approach feasible for a real-world scenario.

The dimensional approach was addressed in Chapter \ref{Chap:Violin}, for the task of the automatic annotation of the violins' timbre. This was a highly limited and difficult scenario, since the timbre is a complex property of the instruments, whose semantics is far from being fully formalized. We tackled the formalization of the semantic domain by designing a dimensional semantic model using a set of six bipolar descriptors, each referring to one specific high-level feature of the timbre. How to link the semantic domain with the signal domain was also obscure. Therefore, we applied a set of machine learning techniques on a automatically-learned feature representation of the signal domain. The evaluation of this approach highlighted one of the main drawbacks of deep learning techniques, which is the need of a tremendous amount of data for their training. Nevertheless, the results exhibited average to high performance, proving the effectiveness of the proposed approach for the task.

The timbre is an important semantic aspects of the songs and the semantic model for the description of the timbre of violins can be easily generalized to describe the timbral qualities of the entire songs, while the meaning of the single descriptors would most likely change. As an example, a \textit{warm} timbre of a violin is different from the \textit{warm} sound of the entire song.. The perceived mood is another relevant aspect for music description, as discussed and studied in Section \ref{sec:HLFs:VA}. A complete semantic model should be capable of capturing all the possible aspects of music description. In order to do so, several approaches have been proposed, based either on the definition of different semantic models for each musical aspect or on the definition of a generic semantic model for the descriptors from all the aspects. Both approaches do not consider the ambiguity commonly occurring in natural language, where each descriptor has a specific semantics within its aspect, and some descriptors can even assume different meanings depending on the aspect they are describing, i.e., on their \textit{context} of use.

In Chapter \ref{Chap:DCSM} we addressed this extremely complex scenario by designing a dimensional semantic model able to deal with the ambiguity and the polysemy (i.e., the terms that assume different semantics in different contexts) of natural language. We formalized the semantic domain with a Dimensional Contextual Semantic Model (DCSM), where each descriptor represents an axis of the space, and the contexts are modeled as possibly overlapping subsets of the vocabulary of descriptors. 
The overlap among contexts allowed to take polysemy into consideration, that is further addressed by defining a different metric of semantic similarity for each context. We evaluated our approach by developing a prototype of a music search engine based on natural-language queries to act as a real-case application for the DCSM. In this application scenario, the linking function was modeled as the system to search into and retrieve items from a music library. We validated our approach by comparing the DCSM with two models that follow the aforementioned approaches: a generic semantic model for all the contexts and a set of different semantic models for each context. A subjective test of the prototypes confirmed the capability of DCSM of handling the issue of polysemy, while the other two models introduced a bias in the description and hence in the retrieval of the songs. 


The formalization of the components of the considered schema led to the investigation and development of novel approaches to understand which musical properties are relevant in different scenarios and how to model the involved semantics. The results obtained in the four aforementioned application scenarios proved the ability and flexibility of the generalization to address the current issues. To conclude, we discuss the future developments of some scenarios from our work. 

With respect to the signal domain, we showed in Chapters \ref{Chap:MSA}, \ref{Chap:Bootleg} and \ref{Chap:Violin} that Deep Belief Networks provide a reliable tool to automatically extract the salient features from the music signal. In future works, we would like to explore deeper and different architectures and to investigate their ability to extract specific patterns from the audio signal. Moreover, we intend to exploit the capability of deep learning techniques of being fine-tuned, i.e., of being trained with a supervised approach for the extraction of target-oriented features. By using fine-tuning, we might be able to extract abstract features specifically designed to address the task of structure analysis or extremely effective for the description of the timbre of violins. This will also lead to overcome the separation between signal domain and linking function, since the learned features will embed the link to a specific semantic domain.

With respect to the semantic domain, in  Chapter \ref{Chap:DCSM} we only scratched the surface of the issues raised by the ambiguities in natural language. In future works, we would like to expand the semantic model by including all the timbral descriptors defined in Chapter \ref{Chap:Violin} and the semantic similarities inferred for the perceived emotion context discussed in Section \ref{sec:HLFs:ANEW}. Moreover, the approach for DCSM heavily relies on prior annotation on the semantics of terms collected via cognitively expensive surveys. Nowadays, there is a tremendous amount of unstructured data that could be gathered from the Internet, such as from reviews on online stores, collaborative encyclopedia projects, comments on lyrics or social networks. We will investigate an approach to automatically infer information on the contexts of terms and their semantic similarity defined for each context from the available data. We also intend to include other musical aspect in the DCSM, such as those related to harmony or music genre. Additionally, we would like to refine the music search engine prototype by including other features from our studies, such as the music structure or the generation process of the songs, in order to allow queries such as \textit{List all the live performances that contain a slow verse and a fast chorus}.
%The prototype will also be helpful to collect of information on the semantic domain of the users' needs.

Finally, in this thesis we deeply analyzed the problems concerning the music art. Nevertheless, the schema we followed can be used for several other fields that concern the human perception. Among such fields, the art of dance is a peculiar scenario, because its domain involves the music that accompanies the dance, as well as the body gestures of dancers \cite{camurri2003multimodal}. The formalization of the signal domain of dance, consequently, raises a number of issues, due to the \textit{multimodality} of signals that need to be captured, such as  motion capturing, video and audio recording, etc. The semantic domain is also difficult to formalize, since each dance genre has its own set of gestures and most of them have not received a complete semantic definition yet. An automatic analysis of the signal and semantic domain of dance is the focus of the Horizon2020 project \textit{WhoLoDance} \cite{WholoDance:2016}. The main purposes of the project are to investigate the body knowledge from a physical and semantic perspective in order to develop tools to innovate the teaching of dance and possibly revolutionize choreography. In future works, we intend to address the multimodality issues of the dance art by exploiting and extending the knowledge acquired for the music analysis. 